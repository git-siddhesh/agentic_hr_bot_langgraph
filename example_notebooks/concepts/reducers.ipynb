{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reducers\n",
    "Reducers are key to understanding how updates from nodes are applied to the State. Each key in the State has its own independent reducer function. If no reducer function is explicitly specified then it is assumed that all updates to that key should override it. There are a few different types of reducers, starting with the default type of reducer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default Reducer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1: Overwrite or Update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, no reducer functions are specified for any key. Let's assume the input to the graph is `{\"foo\": 1, \"bar\": [\"hi\"]}`.  \n",
    "Let's then assume the first Node returns `{\"foo\": 2}`.  \n",
    "This is treated as an update to the state. Notice that the Node does not need to return the whole State schema - just an update.  \n",
    "After applying this update, the State would then be `{\"foo\": 2, \"bar\": [\"hi\"]}`.  \n",
    "If the second node returns {\"bar\": [\"bye\"]} then the State would then be `{\"foo\": 2, \"bar\": [\"bye\"]}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "class State(TypedDict):\n",
    "    foo: int\n",
    "    bar: list[str]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: Reducer function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we've used the Annotated type to specify a reducer function (operator.add) for the second key (bar).   \n",
    "Note that the first key remains unchanged.  \n",
    "Let's assume the input to the graph is {\"foo\": 1, \"bar\": [\"hi\"]}.  \n",
    "Let's then assume the first Node returns {\"foo\": 2}.  \n",
    "This is treated as an update to the state.  \n",
    "Notice that the Node does not need to return the whole State schema - just an update.  \n",
    "After applying this update, the State would then be {\"foo\": 2, \"bar\": [\"hi\"]}.  \n",
    "If the second node returns {\"bar\": [\"bye\"]} then the State would then be {\"foo\": 2, \"bar\": [\"hi\", \"bye\"]}.  \n",
    "Notice here that the bar key is updated by adding the two lists together.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from operator import add\n",
    "\n",
    "class State(TypedDict):\n",
    "    foo: int\n",
    "    bar: Annotated[list[str], add]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> NOTE:  If you don't specify a reducer, every state update will overwrite the list of messages with the most recently provided value. If you wanted to simply append messages to the existing list, you could use operator.add as a reducer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class State(TypedDict):\n",
    "    foo: int\n",
    "    bar: Annotated[list[str], add_messages]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A reducer that can keep track of message IDs and overwrite existing messages, if updated. \n",
    "(Allows to append or update messages in the list)\n",
    "\n",
    "`add_messages` : For brand new messages, it will simply append to existing list, but it will also handle the updates for existing messages correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict, {'foo': 1, 'bar': ['a', 'b']})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = State(foo=1, bar=[\"a\", \"b\"])\n",
    "type(s), s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s['bar']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.GraphState"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Callable, List, Any\n",
    "from langchain_core.messages import AnyMessage, HumanMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class GraphState(dict):\n",
    "    \"\"\"\n",
    "    Manages a dictionary-like structure with automatic message summarization\n",
    "    when the message list exceeds a certain length.\n",
    "    \"\"\"\n",
    "    def __init__(self, limit: int, summarize_func: Callable[[List[HumanMessage]], HumanMessage]):\n",
    "        super().__init__()\n",
    "        self[\"messages\"]: List[HumanMessage] = []\n",
    "        self[\"limit\"] = limit\n",
    "        self.summarize_func = summarize_func\n",
    "\n",
    "    def add_message(self, message: HumanMessage) -> None:\n",
    "        \"\"\"\n",
    "        Adds a message to the list. If the total number of messages exceeds the limit, \n",
    "        triggers summarization.\n",
    "        \"\"\"\n",
    "        self[\"messages\"].append(message)\n",
    "        if len(self[\"messages\"]) > self[\"limit\"]:\n",
    "            self._summarize()\n",
    "\n",
    "    def _summarize(self) -> None:\n",
    "        \"\"\"\n",
    "        Summarizes the messages and reduces the list to a summary and the last few messages.\n",
    "        \"\"\"\n",
    "        # Messages to summarize (all except the last few)\n",
    "        messages_to_summarize = self[\"messages\"][:-self[\"limit\"]]\n",
    "        # Create a summary message using the provided summarization function\n",
    "        summary_message = self.summarize_func(messages_to_summarize)\n",
    "        # Keep the last `limit` messages for context and prepend the summary\n",
    "        self[\"messages\"] = [summary_message] + self[\"messages\"][-self[\"limit\"]:]\n",
    "\n",
    "    # Overriding __getitem__ and __setitem__ for dictionary-like behavior\n",
    "    def __getitem__(self, key: str) -> Any:\n",
    "        return super().__getitem__(key)\n",
    "\n",
    "    def __setitem__(self, key: str, value: Any) -> None:\n",
    "        super().__setitem__(key, value)\n",
    "\n",
    "\n",
    "# Example summarization function\n",
    "def example_summarize_func(messages: List[HumanMessage]) -> HumanMessage:\n",
    "    \"\"\"\n",
    "    Summarizes a list of messages by concatenating their content into a single message.\n",
    "    \"\"\"\n",
    "    summary_content = \" \".join([msg.content for msg in messages])  # Combine all message contents\n",
    "    return HumanMessage(content=f\"Summary: {summary_content}\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "graph_state = GraphState(limit=5, summarize_func=example_summarize_func)\n",
    "type(graph_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [], 'limit': 5}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After adding Message 1: ['Message 1']\n",
      "After adding Message 2: ['Message 1', 'Message 2']\n",
      "After adding Message 3: ['Message 1', 'Message 2', 'Message 3']\n",
      "After adding Message 4: ['Message 1', 'Message 2', 'Message 3', 'Message 4']\n",
      "After adding Message 5: ['Message 1', 'Message 2', 'Message 3', 'Message 4', 'Message 5']\n",
      "After adding Message 6: ['Summary: Message 1', 'Message 2', 'Message 3', 'Message 4', 'Message 5', 'Message 6']\n",
      "After adding Message 7: ['Summary: Summary: Message 1 Message 2', 'Message 3', 'Message 4', 'Message 5', 'Message 6', 'Message 7']\n",
      "After adding Message 8: ['Summary: Summary: Summary: Message 1 Message 2 Message 3', 'Message 4', 'Message 5', 'Message 6', 'Message 7', 'Message 8']\n",
      "After adding Message 9: ['Summary: Summary: Summary: Summary: Message 1 Message 2 Message 3 Message 4', 'Message 5', 'Message 6', 'Message 7', 'Message 8', 'Message 9']\n",
      "After adding Message 10: ['Summary: Summary: Summary: Summary: Summary: Message 1 Message 2 Message 3 Message 4 Message 5', 'Message 6', 'Message 7', 'Message 8', 'Message 9', 'Message 10']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Add example messages\n",
    "for i in range(1, 11):  # Adding 10 messages\n",
    "    graph_state.add_message(HumanMessage(content=f\"Message {i}\"))\n",
    "    print(f\"After adding Message {i}: {[msg.content for msg in graph_state['messages']]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chapter2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
